{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers --quiet\n",
        "\n",
        "import os\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "import random\n",
        "import copy\n",
        "import pickle\n",
        "\n",
        "print(\"DA5401 - Data Challenge\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "id": "hfKJOXMewDDr"
      },
      "id": "hfKJOXMewDDr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "CONFIG = {\n",
        "    'data_dir': '/kaggle/input/da5401-2025-data-challenge',\n",
        "    'output_dir': '/kaggle/working',\n",
        "    'encoder_name': 'paraphrase-multilingual-mpnet-base-v2',\n",
        "\n",
        "    # Training\n",
        "    'batch_size': 64,\n",
        "    'learning_rate': 1e-4,  # Head LR (encoder will use smaller via param groups)\n",
        "    'epochs': 100,\n",
        "    'dropout': 0.4,\n",
        "    'patience': 20,\n",
        "    'weight_decay': 1e-5,\n",
        "\n",
        "    # Model\n",
        "    'model_type': 'heteroscedastic',  # 'standard', 'ordinal', 'heteroscedastic' (Option 3: better for uncertainty)\n",
        "    'embedding_dim': 768,\n",
        "    'hidden_dims': [512, 256, 128],\n",
        "\n",
        "    # Advanced Features\n",
        "    'fine_tune_encoder': True,\n",
        "    'encoder_ft_epochs': 3,  # Epochs for encoder fine-tuning\n",
        "    'encoder_ft_lr': 2e-5,  # Small encoder LR (much smaller than head LR)\n",
        "    'encoder_ft_batch_size': 64,\n",
        "\n",
        "    'use_ensemble': False,\n",
        "    'n_cv_folds': 5,\n",
        "    'cv_random_state': 42,  # Random state for consistent folds\n",
        "    'ensemble_configs': [],\n",
        "\n",
        "    # Data Augmentation (Option 2: Synthetic Negatives)\n",
        "    'use_synthetic_negatives': True,  # Helps with class imbalance\n",
        "    'synthetic_ratio': 0.10,  #  prevent over-biasing toward low scores\n",
        "    'synthetic_score_range': (1, 6),  # Focused on very low scores (1-6) to avoid biasing away from 9-10\n",
        "\n",
        "    # Loss (use heteroscedastic for Option 3)\n",
        "    'loss_type': 'heteroscedastic',  # 'ordinal', 'hybrid', 'focal', 'ce', or 'heteroscedastic' (Option 3)\n",
        "    'focal_gamma': 2.0,\n",
        "    'hybrid_mse_weight': 0.15,  # more emphasis on regression aspect\n",
        "    'use_clipped_weights': True,\n",
        "    'use_weights': True,  # Apply sample weights to loss\n",
        "    'max_weight': 3.0,  # less aggressive weighting\n",
        "    'min_weight': 0.5,\n",
        "    # Special weighting for high scores to prevent under-prediction\n",
        "    'boost_high_scores': True,  # Additional weight boost for scores 9-10\n",
        "    'sample_weight_temp': 0.5,  # Temperature for weight calculation\n",
        "\n",
        "    # Checkpointing\n",
        "    'resume_from_checkpoint': True,\n",
        "    'checkpoint_dir': '/kaggle/working/checkpoints',\n",
        "    'save_interval': 10,\n",
        "    'auto_save': True,\n",
        "\n",
        "    # Advanced\n",
        "    'use_amp': True,\n",
        "    'gradient_clip': 1.0,\n",
        "    'min_lr': 1e-6,\n",
        "    'lr_patience': 5,\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG['checkpoint_dir'], exist_ok=True)"
      ],
      "metadata": {
        "id": "zYRkQbCFwJWd"
      },
      "id": "zYRkQbCFwJWd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ADVANCED LOSSES\n",
        "# ============================================================================\n",
        "\n",
        "class OrdinalRegressionLoss(nn.Module):\n",
        "    \"\"\"Ordinal regression loss for ordered classes.\"\"\"\n",
        "\n",
        "    def __init__(self, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, target, sample_weights=None, return_per_sample=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            logits: (batch_size, 11) logits for cumulative probabilities\n",
        "            target: (batch_size,) integer targets in [0, 10]\n",
        "            sample_weights: (batch_size,) optional sample weights\n",
        "            return_per_sample: if True, return per-sample losses without reduction\n",
        "        \"\"\"\n",
        "        batch_size = logits.shape[0]\n",
        "        targets_cum = torch.zeros_like(logits)\n",
        "\n",
        "        # Create cumulative targets: P(score <= k) = 1 for k >= target\n",
        "        for i in range(batch_size):\n",
        "            k = target[i].item()\n",
        "            targets_cum[i, :k+1] = 1.0\n",
        "\n",
        "        # Compute BCE loss per sample\n",
        "        bce_per_sample = F.binary_cross_entropy_with_logits(\n",
        "            logits, targets_cum, reduction='none'\n",
        "        )\n",
        "        # Average over the 11 thresholds\n",
        "        loss_per_sample = bce_per_sample.mean(dim=1)\n",
        "\n",
        "        # Apply sample weights if provided\n",
        "        if sample_weights is not None:\n",
        "            loss_per_sample = loss_per_sample * sample_weights\n",
        "\n",
        "        if return_per_sample:\n",
        "            return loss_per_sample\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss_per_sample.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss_per_sample.sum()\n",
        "        else:\n",
        "            return loss_per_sample\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal loss for imbalanced data.\"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1.0, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        ce = F.cross_entropy(logits, target, reduction='none')\n",
        "        pt = torch.exp(-ce)\n",
        "        return (self.alpha * (1 - pt) ** self.gamma * ce).mean()\n",
        "\n",
        "\n",
        "class WeightedFocalLoss(nn.Module):\n",
        "    \"\"\"Focal loss with clipped sample weights.\"\"\"\n",
        "\n",
        "    def __init__(self, gamma=2.0, max_weight=5.0, min_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.max_weight = max_weight\n",
        "        self.min_weight = min_weight\n",
        "\n",
        "    def forward(self, logits, target, sample_weights):\n",
        "        ce = F.cross_entropy(logits, target, reduction='none')\n",
        "        pt = torch.exp(-ce)\n",
        "        focal_weight = (1 - pt) ** self.gamma\n",
        "\n",
        "        combined_weights = sample_weights * focal_weight\n",
        "        combined_weights = torch.clamp(combined_weights, self.min_weight, self.max_weight)\n",
        "\n",
        "        return (ce * combined_weights).mean()\n",
        "\n",
        "\n",
        "class HybridLoss(nn.Module):\n",
        "    \"\"\"Combination of CrossEntropyLoss and MSE on expected score (more stable than ordinal alone).\"\"\"\n",
        "\n",
        "    def __init__(self, ce_weight=1.0, mse_weight=0.1):\n",
        "        super().__init__()\n",
        "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "        self.mse_weight = mse_weight\n",
        "        self.ce_weight = ce_weight\n",
        "\n",
        "    def forward(self, logits, target, sample_weights=None, return_per_sample=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            logits: (batch_size, 11) class logits\n",
        "            target: (batch_size,) integer targets in [0, 10]\n",
        "            sample_weights: (batch_size,) optional sample weights\n",
        "            return_per_sample: if True, return per-sample losses without reduction\n",
        "        \"\"\"\n",
        "        # CrossEntropyLoss\n",
        "        ce = self.ce_loss(logits, target)  # (B,)\n",
        "\n",
        "        # MSE on expected score\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        expected_scores = torch.sum(probs * torch.arange(11, device=logits.device).float(), dim=1)\n",
        "        target_float = target.float()\n",
        "        mse = (expected_scores - target_float) ** 2  # (B,)\n",
        "\n",
        "        # Combined loss per sample\n",
        "        loss_per_sample = self.ce_weight * ce + self.mse_weight * mse\n",
        "\n",
        "        # Apply sample weights if provided\n",
        "        if sample_weights is not None:\n",
        "            loss_per_sample = loss_per_sample * sample_weights\n",
        "\n",
        "        if return_per_sample:\n",
        "            return loss_per_sample\n",
        "\n",
        "        return loss_per_sample.mean()\n",
        "\n",
        "\n",
        "class HeteroscedasticLoss(nn.Module):\n",
        "    \"\"\"Heteroscedastic loss: models both mean and uncertainty (logvar).\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, mean, logvar, target, sample_weights=None, return_per_sample=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mean: (batch_size,) predicted mean scores\n",
        "            logvar: (batch_size,) predicted log-variance\n",
        "            target: (batch_size,) integer targets in [0, 10]\n",
        "            sample_weights: (batch_size,) optional sample weights\n",
        "            return_per_sample: if True, return per-sample losses without reduction\n",
        "        \"\"\"\n",
        "        target_float = target.float()\n",
        "        variance = torch.exp(logvar)\n",
        "\n",
        "        # Heteroscedastic loss: MSE weighted by inverse variance + penalty for high variance\n",
        "        precision = 1.0 / (variance + 1e-6)\n",
        "        squared_error = (mean - target_float) ** 2\n",
        "        loss_per_sample = precision * squared_error + logvar\n",
        "\n",
        "        # Apply sample weights if provided\n",
        "        if sample_weights is not None:\n",
        "            loss_per_sample = loss_per_sample * sample_weights\n",
        "\n",
        "        if return_per_sample:\n",
        "            return loss_per_sample\n",
        "\n",
        "        return loss_per_sample.mean()"
      ],
      "metadata": {
        "id": "moFxOnWcwNu7"
      },
      "id": "moFxOnWcwNu7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# UNIFIED LOSS COMPUTATION\n",
        "# ============================================================================\n",
        "\n",
        "def compute_weighted_loss(criterion, logits_or_tuple, target, sample_weights):\n",
        "    \"\"\"\n",
        "    Unified helper to compute per-sample losses, apply sample weights, and reduce.\n",
        "\n",
        "    Args:\n",
        "        criterion: Loss function instance (HybridLoss, OrdinalRegressionLoss, FocalLoss,\n",
        "                   HeteroscedasticLoss, or CrossEntropyLoss)\n",
        "        logits_or_tuple: If heteroscedastic -> (mean, logvar), else logits tensor\n",
        "        target: LongTensor (B,)\n",
        "        sample_weights: FloatTensor (B,) or None\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss tensor\n",
        "    \"\"\"\n",
        "    # Heteroscedastic expects (mean, logvar)\n",
        "    if isinstance(criterion, HeteroscedasticLoss):\n",
        "        mean, logvar = logits_or_tuple\n",
        "        loss_per_sample = criterion(mean, logvar, target, sample_weights=None, return_per_sample=True)\n",
        "        if sample_weights is not None:\n",
        "            loss_per_sample = loss_per_sample * sample_weights\n",
        "        return loss_per_sample.mean()\n",
        "\n",
        "    # For others, compute per-sample losses\n",
        "    if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "        # CrossEntropyLoss defaults to 'mean' reduction - use 'none'\n",
        "        loss_per_sample = F.cross_entropy(logits_or_tuple, target, reduction='none')\n",
        "    elif isinstance(criterion, (HybridLoss, OrdinalRegressionLoss)):\n",
        "        # These support return_per_sample\n",
        "        loss_per_sample = criterion(logits_or_tuple, target, sample_weights=None, return_per_sample=True)\n",
        "    elif isinstance(criterion, FocalLoss):\n",
        "        # FocalLoss needs per-sample CE first\n",
        "        ce = F.cross_entropy(logits_or_tuple, target, reduction='none')\n",
        "        pt = torch.exp(-ce)\n",
        "        loss_per_sample = criterion.alpha * (1 - pt) ** criterion.gamma * ce\n",
        "    elif isinstance(criterion, WeightedFocalLoss):\n",
        "        # WeightedFocalLoss applies weights internally but we want per-sample\n",
        "        ce = F.cross_entropy(logits_or_tuple, target, reduction='none')\n",
        "        pt = torch.exp(-ce)\n",
        "        focal_weight = (1 - pt) ** criterion.gamma\n",
        "        combined_weights = sample_weights * focal_weight if sample_weights is not None else focal_weight\n",
        "        combined_weights = torch.clamp(combined_weights, criterion.min_weight, criterion.max_weight)\n",
        "        loss_per_sample = ce * combined_weights\n",
        "    else:\n",
        "        # Fallback: try to get per-sample loss\n",
        "        try:\n",
        "            # Try calling with reduction='none' if possible\n",
        "            if hasattr(criterion, 'reduction'):\n",
        "                old_reduction = criterion.reduction\n",
        "                criterion.reduction = 'none'\n",
        "                loss_per_sample = criterion(logits_or_tuple, target)\n",
        "                criterion.reduction = old_reduction\n",
        "            else:\n",
        "                # Last resort: compute mean then expand (not ideal but works)\n",
        "                loss_scalar = criterion(logits_or_tuple, target)\n",
        "                loss_per_sample = loss_scalar.expand(logits_or_tuple.shape[0])\n",
        "        except:\n",
        "            # If all else fails, return a scalar (weighting won't work but training continues)\n",
        "            return criterion(logits_or_tuple, target)\n",
        "\n",
        "    # Apply sample weights if provided\n",
        "    if sample_weights is not None:\n",
        "        loss_per_sample = loss_per_sample * sample_weights\n",
        "\n",
        "    # Reduce to scalar\n",
        "    return loss_per_sample.mean()"
      ],
      "metadata": {
        "id": "MHIE8VREwQY7"
      },
      "id": "MHIE8VREwQY7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ORDINAL MODEL\n",
        "# ============================================================================\n",
        "\n",
        "class OrdinalMetricMatchingModel(nn.Module):\n",
        "    \"\"\"Ordinal regression model.\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim=768, hidden_dims=[512, 256, 128], dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.bilinear = nn.Bilinear(embedding_dim, embedding_dim, embedding_dim)\n",
        "\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.layer_norms = nn.ModuleList()\n",
        "        input_dim = embedding_dim * 3\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            self.fc_layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.layer_norms.append(nn.LayerNorm(hidden_dim))\n",
        "            input_dim = hidden_dim\n",
        "\n",
        "        self.output = nn.Linear(input_dim, 11)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, metric_emb, text_emb):\n",
        "        bilinear_out = self.bilinear(metric_emb, text_emb)\n",
        "        combined = torch.cat([metric_emb, text_emb, bilinear_out], dim=1)\n",
        "\n",
        "        x = combined\n",
        "        for fc, ln in zip(self.fc_layers[:-1], self.layer_norms[:-1]):\n",
        "            x = fc(x)\n",
        "            x = ln(x)\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.fc_layers[-1](x)\n",
        "        x = self.layer_norms[-1](x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return self.output(x)\n",
        "\n",
        "    def predict_score(self, metric_emb, text_emb):\n",
        "        \"\"\"Predict score from ordinal cumulative logits.\n",
        "\n",
        "        Converts cumulative probabilities P(score <= k) to per-class probabilities.\n",
        "        \"\"\"\n",
        "        logits = self.forward(metric_emb, text_emb)\n",
        "        cum_probs = torch.sigmoid(logits)  # shape (B, 11) representing P(score <= k) for k=0..10\n",
        "\n",
        "        # Convert cumulative probs to per-class probs\n",
        "        probs = torch.zeros_like(cum_probs)\n",
        "        probs[:, 0] = cum_probs[:, 0]  # P(score = 0) = P(score <= 0)\n",
        "\n",
        "        # For k=1..10: P(score = k) = P(score <= k) - P(score <= k-1)\n",
        "        for k in range(1, cum_probs.shape[1]):  # 1..10 inclusive\n",
        "            probs[:, k] = cum_probs[:, k] - cum_probs[:, k-1]\n",
        "\n",
        "        # Numeric safety & renormalize\n",
        "        probs = torch.clamp(probs, min=0.0)\n",
        "        probs = probs / (probs.sum(dim=1, keepdim=True) + 1e-8)\n",
        "\n",
        "        # Compute expected score\n",
        "        expected_score = torch.sum(probs * torch.arange(probs.shape[1], device=metric_emb.device).float(), dim=1)\n",
        "        return torch.clamp(expected_score, 0.0, 10.0)\n",
        "\n",
        "\n",
        "class StandardMetricMatchingModel(nn.Module):\n",
        "    \"\"\"Standard classification model.\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim=768, hidden_dims=[512, 256, 128], dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.bilinear = nn.Bilinear(embedding_dim, embedding_dim, embedding_dim)\n",
        "\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.layer_norms = nn.ModuleList()\n",
        "        input_dim = embedding_dim * 3\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            self.fc_layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.layer_norms.append(nn.LayerNorm(hidden_dim))\n",
        "            input_dim = hidden_dim\n",
        "\n",
        "        self.output = nn.Linear(input_dim, 11)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, metric_emb, text_emb):\n",
        "        bilinear_out = self.bilinear(metric_emb, text_emb)\n",
        "        combined = torch.cat([metric_emb, text_emb, bilinear_out], dim=1)\n",
        "\n",
        "        x = combined\n",
        "        for fc, ln in zip(self.fc_layers[:-1], self.layer_norms[:-1]):\n",
        "            x = fc(x)\n",
        "            x = ln(x)\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.fc_layers[-1](x)\n",
        "        x = self.layer_norms[-1](x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return self.output(x)\n",
        "\n",
        "    def predict_score(self, metric_emb, text_emb):\n",
        "        logits = self.forward(metric_emb, text_emb)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        expected_score = torch.sum(probs * torch.arange(11, device=metric_emb.device).float(), dim=1)\n",
        "        return expected_score\n",
        "\n",
        "\n",
        "class HeteroscedasticMatchingModel(nn.Module):\n",
        "    \"\"\"Heteroscedastic regression model: predicts mean (mu) and log-variance (logvar).\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim=768, hidden_dims=[512, 256, 128], dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.bilinear = nn.Bilinear(embedding_dim, embedding_dim, embedding_dim)\n",
        "\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.layer_norms = nn.ModuleList()\n",
        "        input_dim = embedding_dim * 3\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            self.fc_layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.layer_norms.append(nn.LayerNorm(hidden_dim))\n",
        "            input_dim = hidden_dim\n",
        "\n",
        "        # Two outputs: mean and log-variance\n",
        "        self.mean_head = nn.Linear(input_dim, 1)\n",
        "        self.logvar_head = nn.Linear(input_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, metric_emb, text_emb):\n",
        "        bilinear_out = self.bilinear(metric_emb, text_emb)\n",
        "        combined = torch.cat([metric_emb, text_emb, bilinear_out], dim=1)\n",
        "\n",
        "        x = combined\n",
        "        for fc, ln in zip(self.fc_layers[:-1], self.layer_norms[:-1]):\n",
        "            x = fc(x)\n",
        "            x = ln(x)\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.fc_layers[-1](x)\n",
        "        x = self.layer_norms[-1](x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        mean = self.mean_head(x)\n",
        "        logvar = self.logvar_head(x)\n",
        "\n",
        "        # Clip logvar to prevent extremes (recommended: [-10, 10])\n",
        "        logvar = torch.clamp(logvar, -10.0, 10.0)\n",
        "\n",
        "        return mean.squeeze(-1), logvar.squeeze(-1)\n",
        "\n",
        "    def predict_score(self, metric_emb, text_emb):\n",
        "        \"\"\"Predict expected mean score.\"\"\"\n",
        "        mean, logvar = self.forward(metric_emb, text_emb)\n",
        "        return mean"
      ],
      "metadata": {
        "id": "qLG2qLTCwXcB"
      },
      "id": "qLG2qLTCwXcB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SIMCSE-STYLE CONTRASTIVE LEARNING\n",
        "# ============================================================================\n",
        "\n",
        "def combine_text_fields(record):\n",
        "    \"\"\"Helper function to combine text fields from a record.\"\"\"\n",
        "    parts = []\n",
        "    if record.get('system_prompt'): parts.append(record['system_prompt'])\n",
        "    if record.get('user_prompt'): parts.append(record['user_prompt'])\n",
        "    elif record.get('prompt'): parts.append(record['prompt'])\n",
        "    if record.get('response'): parts.append(record['response'])\n",
        "    elif record.get('expected_response'): parts.append(record['expected_response'])\n",
        "    return ' '.join(parts)\n",
        "\n",
        "\n",
        "def fine_tune_encoder_simcse(text_encoder, train_data, device, epochs=3, batch_size=64, lr=2e-5):\n",
        "    \"\"\"\n",
        "    Improved SimCSE-style contrastive fine-tuning using SentenceTransformer.fit() API.\n",
        "\n",
        "    Updates:\n",
        "    - Uses MultipleNegativesRankingLoss (recommended for large batches)\n",
        "    - Larger batch size (64) or gradient accumulation to simulate 128-256\n",
        "    - Proper warmup_steps calculation (~10% of total steps)\n",
        "    - Falls back to ContrastiveLoss if MultipleNegativesRankingLoss fails\n",
        "\n",
        "    References:\n",
        "    - https://sbert.net/examples/training/unsupervised_learning/README.html#simcse\n",
        "    - https://www.pinecone.io/learn/series/nlp/fine-tune-sentence-transformers-mnr/\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"SimCSE-Style Contrastive Fine-tuning of Text Encoder\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Disable wandb using the recommended approach (report_to='none')\n",
        "    os.environ['WANDB_DISABLED'] = 'true'\n",
        "    os.environ['TRANSFORMERS_VERBOSITY'] = 'error'\n",
        "\n",
        "    # Prepare InputExamples - create positive pairs (same sentence for SimCSE)\n",
        "    # SimCSE: positive pair = same sentence encoded twice with different dropout\n",
        "    texts = [combine_text_fields(rec) for rec in train_data]\n",
        "    # Create pairs: each text paired with itself (positive pair)\n",
        "    # The ContrastiveLoss will use dropout to create different embeddings\n",
        "    examples = [InputExample(texts=[t, t], label=1.0) for t in texts]\n",
        "\n",
        "    # Create DataLoader\n",
        "    from torch.utils.data import DataLoader as TorchDataLoader\n",
        "    train_dataloader = TorchDataLoader(examples, shuffle=True, batch_size=batch_size, drop_last=False)\n",
        "\n",
        "    # Calculate warmup_steps (recommended: ~10% of total steps)\n",
        "    num_steps = len(train_dataloader) * epochs\n",
        "    warmup_steps = max(100, num_steps // 10)\n",
        "\n",
        "    # Prefer MultipleNegativesRankingLoss (better for large batches)\n",
        "    # Falls back to ContrastiveLoss if needed\n",
        "    try:\n",
        "        train_loss = losses.MultipleNegativesRankingLoss(model=text_encoder)\n",
        "        loss_name = \"MultipleNegativesRankingLoss\"\n",
        "        print(f\"Using {loss_name} (recommended for large batches)\")\n",
        "    except Exception as e:\n",
        "        train_loss = losses.ContrastiveLoss(model=text_encoder)\n",
        "        loss_name = \"ContrastiveLoss\"\n",
        "        print(f\"Using {loss_name} (fallback): {e}\")\n",
        "\n",
        "    print(f\"Total steps: {num_steps}, Warmup steps: {warmup_steps}\")\n",
        "\n",
        "    # Fine-tune using SentenceTransformer.fit() API\n",
        "    output_dir_ft = os.path.join(CONFIG['output_dir'], 'encoder_finetune')\n",
        "    os.makedirs(output_dir_ft, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        text_encoder.fit(\n",
        "            train_objectives=[(train_dataloader, train_loss)],\n",
        "            epochs=epochs,\n",
        "            warmup_steps=warmup_steps,  # Proper warmup calculation\n",
        "            optimizer_params={'lr': lr},\n",
        "            show_progress_bar=True,\n",
        "            output_path=output_dir_ft,\n",
        "            use_amp=CONFIG.get('use_amp', True)\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # If fit() still has issues, fall back to simpler approach\n",
        "        print(f\"Warning: SentenceTransformer.fit() failed: {e}\")\n",
        "        print(\"Skipping encoder fine-tuning, using pre-trained encoder as-is\")\n",
        "        return text_encoder\n",
        "\n",
        "    print(f\"Encoder fine-tuning completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return text_encoder"
      ],
      "metadata": {
        "id": "4j3o8xkHwcrr"
      },
      "id": "4j3o8xkHwcrr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DATASET WITH WEIGHTS\n",
        "# ============================================================================\n",
        "\n",
        "class WeightedDataset(Dataset):\n",
        "    def __init__(self, data, metric_embeddings, metric_names_map, text_embeddings, score_weights):\n",
        "        self.data = data\n",
        "        self.metric_embeddings = torch.FloatTensor(metric_embeddings)\n",
        "        self.metric_names_map = metric_names_map\n",
        "        self.text_embeddings = torch.FloatTensor(text_embeddings)\n",
        "        self.score_weights = score_weights\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        record = self.data[idx]\n",
        "        metric_idx = self.metric_names_map[record['metric_name']]\n",
        "        metric_emb = self.metric_embeddings[metric_idx]\n",
        "        text_emb = self.text_embeddings[idx]\n",
        "\n",
        "        if 'score' in record:\n",
        "            score = int(float(record['score']))\n",
        "            weight = self.score_weights[score] if self.score_weights else 1.0\n",
        "            return metric_emb, text_emb, score, weight, idx\n",
        "        return metric_emb, text_emb, idx\n",
        "\n"
      ],
      "metadata": {
        "id": "3LcpJgZqwiVB"
      },
      "id": "3LcpJgZqwiVB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CHECKPOINT MANAGEMENT\n",
        "# ============================================================================\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, best_rmse, filepath):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'best_rmse': best_rmse,\n",
        "        'config': CONFIG,\n",
        "    }\n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"Checkpoint saved: {filepath}\")\n",
        "\n",
        "def load_checkpoint(filepath, model, optimizer=None):\n",
        "    if not os.path.exists(filepath):\n",
        "        return None, 0, float('inf')\n",
        "\n",
        "    checkpoint = torch.load(filepath, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    return model, checkpoint['epoch'] + 1, checkpoint['best_rmse']\n",
        "\n",
        "def find_latest_checkpoint(checkpoint_dir):\n",
        "\n",
        "    priority_paths = [\n",
        "        '/kaggle/input/best-model-final/checkpoints/best_model_synth.pth',\n",
        "        '/kaggle/input/best-model-final/best_model_synth.pth',\n",
        "    ]\n",
        "\n",
        "    # Check priority paths first\n",
        "    for path in priority_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"Found checkpoint at: {path}\")\n",
        "            return path\n",
        "\n",
        "    # Fall back to standard checkpoint directory\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        return None\n",
        "\n",
        "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
        "    if not checkpoints:\n",
        "        return None\n",
        "\n",
        "    checkpoints.sort(key=lambda x: os.path.getmtime(os.path.join(checkpoint_dir, x)))\n",
        "    return os.path.join(checkpoint_dir, checkpoints[-1])\n",
        "\n"
      ],
      "metadata": {
        "id": "3hzcsMgewnbf"
      },
      "id": "3hzcsMgewnbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LOAD DATA\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nLoading data...\")\n",
        "\n",
        "data_dir = None\n",
        "with open(os.path.join(data_dir, 'train_data.json'), encoding='utf-8') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(os.path.join(data_dir, 'metric_names.json'), encoding='utf-8') as f:\n",
        "    metric_names = json.load(f)\n",
        "\n",
        "metric_embeddings = np.load(os.path.join(data_dir, 'metric_name_embeddings.npy'))\n",
        "\n",
        "print(f\"Loaded {len(train_data)} training samples\")\n"
      ],
      "metadata": {
        "id": "jrTDlAPnwupt"
      },
      "id": "jrTDlAPnwupt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# OPTION 2: ADD SYNTHETIC NEGATIVES (BEFORE ENCODING)\n",
        "# ============================================================================\n",
        "\n",
        "if CONFIG.get('use_synthetic_negatives', False):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Generating Synthetic Negatives (Option 2)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get all unique metric names\n",
        "    with open(os.path.join(CONFIG['data_dir'], 'metric_names.json'), encoding='utf-8') as f:\n",
        "        metric_names_list = json.load(f)\n",
        "\n",
        "    # Create synthetic negatives by misaligning metrics with prompts\n",
        "    num_synthetic = int(len(train_data) * CONFIG.get('synthetic_ratio', 0.08))\n",
        "    synthetic_negatives = []\n",
        "\n",
        "    print(f\"Creating {num_synthetic} synthetic negative samples...\")\n",
        "    print(\"  (Misaligning metrics with prompt-response pairs to create low-fitness examples)\")\n",
        "    for _ in tqdm(range(num_synthetic), desc=\"Generating\"):\n",
        "        # Pick a random training sample\n",
        "        base_sample = random.choice(train_data)\n",
        "        synthetic = copy.deepcopy(base_sample)\n",
        "\n",
        "        # Replace metric with a random OTHER metric (misalignment)\n",
        "        # This creates low-fitness pairs that the model should predict low scores for\n",
        "        other_metrics = [m for m in metric_names_list if m != synthetic['metric_name']]\n",
        "        synthetic['metric_name'] = random.choice(other_metrics)\n",
        "\n",
        "        # Assign a low score (1-5 range)\n",
        "        synthetic['score'] = str(float(random.randint(*CONFIG.get('synthetic_score_range', (1, 5)))))\n",
        "\n",
        "        synthetic_negatives.append(synthetic)\n",
        "\n",
        "    # Add synthetic samples to training data\n",
        "    train_data_extended = train_data + synthetic_negatives\n",
        "    print(f\"✓ Added {len(synthetic_negatives)} synthetic negatives\")\n",
        "    print(f\"  Total training samples: {len(train_data)} → {len(train_data_extended)}\")\n",
        "\n",
        "    # Show distribution before/after\n",
        "    scores_original = [int(float(rec['score'])) for rec in train_data]\n",
        "    scores_extended = [int(float(rec['score'])) for rec in train_data_extended]\n",
        "    counts_original = Counter(scores_original)\n",
        "    counts_extended = Counter(scores_extended)\n",
        "\n",
        "    print(\"\\nDistribution BEFORE synthetic negatives:\")\n",
        "    for score in sorted(counts_original.keys()):\n",
        "        count = counts_original[score]\n",
        "        pct = 100 * count / len(scores_original)\n",
        "        print(f\"  Score {score}: {count:5d} ({pct:5.2f}%)\")\n",
        "\n",
        "    print(\"\\nDistribution AFTER synthetic negatives:\")\n",
        "    for score in sorted(counts_extended.keys()):\n",
        "        count = counts_extended[score]\n",
        "        pct = 100 * count / len(scores_extended)\n",
        "        print(f\"  Score {score}: {count:5d} ({pct:5.2f}%)\")\n",
        "\n",
        "    # Use extended data\n",
        "    train_data = train_data_extended\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7cGULZfDwzBN"
      },
      "id": "7cGULZfDwzBN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# OPTION 1: COMPUTE IMPROVED SAMPLE WEIGHTS (SQRT INVERSE FREQUENCY)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nComputing improved sample weights (sqrt inverse frequency)...\")\n",
        "scores = [int(float(rec['score'])) for rec in train_data]\n",
        "score_counts = Counter(scores)\n",
        "\n",
        "score_weights = {}\n",
        "max_count = max(score_counts.values())\n",
        "\n",
        "print(\"Original training distribution:\")\n",
        "for score in sorted(score_counts.keys()):\n",
        "    count = score_counts[score]\n",
        "    pct = 100 * count / len(scores)\n",
        "    print(f\"  Score {score}: {count:5d} ({pct:5.2f}%)\")\n",
        "\n",
        "print(\"\\nComputed weights (sqrt inverse frequency, max 8.0):\")\n",
        "for score in range(11):\n",
        "    count = score_counts.get(score, 1)\n",
        "    # Use sqrt of inverse frequency (more aggressive upweighting)\n",
        "    weight = (max_count / count) ** 0.5\n",
        "    # Clip to 8.0 max (allows higher weights for very rare scores)\n",
        "    weight = min(8.0, weight)\n",
        "\n",
        "    # Boost high scores (9-10) if enabled to prevent under-prediction\n",
        "    if CONFIG.get('boost_high_scores', False):\n",
        "        if score == 9:\n",
        "            # Give score 9 a moderate boost (it's common but model under-predicts it)\n",
        "            weight *= 1.5  # Boost by 50%\n",
        "        elif score == 10:\n",
        "            # Give score 10 a boost (common but model under-predicts it)\n",
        "            weight *= 1.3  # Boost by 30%\n",
        "        # Clip again after boosting\n",
        "        weight = min(8.0, weight)\n",
        "\n",
        "    score_weights[score] = weight\n",
        "    boost_note = \" [boosted]\" if (CONFIG.get('boost_high_scores', False) and score in [9, 10]) else \"\"\n",
        "    print(f\"  Score {score}: count={count:4d}, weight={weight:.3f}{boost_note}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "213brkvKw2Q3"
      },
      "id": "213brkvKw2Q3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ENCODE TEXTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nLoading text encoder...\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Check if fine-tuned encoder already exists (for checkpoint resumption)\n",
        "encoder_finetune_path = os.path.join(CONFIG['output_dir'], 'encoder_finetune')\n",
        "encoder_exists = False\n",
        "encoder_path_to_use = None\n",
        "\n",
        "if encoder_exists:\n",
        "    print(f\"Found existing fine-tuned encoder at: {encoder_path_to_use}\")\n",
        "    print(\"Loading saved encoder (skipping fine-tuning)...\")\n",
        "    text_encoder = SentenceTransformer(encoder_path_to_use)\n",
        "    text_encoder = text_encoder.to(device)\n",
        "    print(\" Loaded fine-tuned encoder from checkpoint\")\n",
        "else:\n",
        "    # Load base encoder\n",
        "    print(f\"Note: Fine-tuned encoder not found at: {encoder_finetune_path}\")\n",
        "    print(\"  (This is normal for fresh runs - encoder will be fine-tuned)\")\n",
        "    print(\"  To skip fine-tuning, upload encoder_finetune/ as a Kaggle dataset\")\n",
        "    text_encoder = SentenceTransformer(CONFIG['encoder_name'])\n",
        "    text_encoder = text_encoder.to(device)\n",
        "\n",
        "    # SimCSE-style contrastive fine-tuning if enabled\n",
        "    if CONFIG.get('fine_tune_encoder', False):\n",
        "        print(\"\\nStarting encoder fine-tuning (this will take a few minutes)...\")\n",
        "        text_encoder = fine_tune_encoder_simcse(\n",
        "            text_encoder, train_data, device,\n",
        "            epochs=CONFIG.get('encoder_ft_epochs', 3),\n",
        "            lr=CONFIG.get('encoder_ft_lr', 2e-5),\n",
        "            batch_size=32\n",
        "        )\n",
        "    else:\n",
        "        print(\" Loaded base encoder (fine-tuning disabled)\")\n",
        "\n",
        "print(\"Encoding text sequences...\")\n",
        "combined_texts = [combine_text_fields(rec) for rec in train_data]\n",
        "\n",
        "# Use explicit device string ('cuda' or 'cpu') for consistent behavior\n",
        "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "text_embeddings = text_encoder.encode(\n",
        "    combined_texts,\n",
        "    show_progress_bar=True,\n",
        "    batch_size=64,  # Reduced from 128 to prevent OOM\n",
        "    device=device_str  # Explicit 'cuda' or 'cpu' for clarity and version compatibility\n",
        ")\n",
        "\n",
        "# Clear GPU memory after encoding if SimCSE fine-tuning not needed\n",
        "# (Text encoder will be reloaded for SimCSE if enabled)\n",
        "if not CONFIG.get('fine_tune_encoder', False):\n",
        "    del text_encoder\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\" Text encoder freed from GPU (not needed for training)\")\n",
        "else:\n",
        "    # Even if fine-tuning, clear cache to free up memory\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\" GPU cache cleared after encoding\")\n"
      ],
      "metadata": {
        "id": "sw-T3YzuxFFJ"
      },
      "id": "sw-T3YzuxFFJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PREPARE DATASET\n",
        "# ============================================================================\n",
        "\n",
        "metric_names_map = {name: idx for idx, name in enumerate(metric_names)}\n",
        "full_dataset = WeightedDataset(train_data, metric_embeddings, metric_names_map, text_embeddings, score_weights)\n",
        "targets = [int(float(rec['score'])) for rec in train_data]\n",
        "\n",
        "# Create consistent CV folds (saved for reproducibility)\n",
        "skf = StratifiedKFold(\n",
        "    n_splits=CONFIG.get('n_cv_folds', 5),\n",
        "    shuffle=True,\n",
        "    random_state=CONFIG.get('cv_random_state', 42)\n",
        ")\n",
        "# Generate all folds for ensemble training\n",
        "all_folds = list(skf.split(range(len(train_data)), targets))\n",
        "\n",
        "# For single model: use first fold\n",
        "train_idx, val_idx = all_folds[0]\n",
        "\n",
        "# Save fold indices for reproducibility (using pickle for Python objects)\n",
        "fold_indices_path = os.path.join(CONFIG['output_dir'], 'cv_folds.pkl')\n",
        "with open(fold_indices_path, 'wb') as f:\n",
        "    pickle.dump(all_folds, f)\n",
        "print(f\"✓ Saved CV fold indices to: {fold_indices_path}\")\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(full_dataset, train_idx)\n",
        "val_dataset = torch.utils.data.Subset(full_dataset, val_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)  # Use 0 for Kaggle compatibility\n",
        "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)  # Use 0 for Kaggle compatibility\n",
        "\n",
        "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lqZW63SPxHcD"
      },
      "id": "lqZW63SPxHcD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INITIALIZE MODEL\n",
        "# ============================================================================\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Automatically select model type based on loss type for compatibility\n",
        "# Hybrid loss requires standard classification logits, not ordinal cumulative logits\n",
        "effective_model_type = CONFIG['model_type']\n",
        "if CONFIG['model_type'] == 'heteroscedastic':\n",
        "    effective_model_type = 'heteroscedastic'\n",
        "elif CONFIG['loss_type'] == 'hybrid' or CONFIG['loss_type'] == 'ce' or CONFIG['loss_type'] == 'focal':\n",
        "    effective_model_type = 'standard'\n",
        "if CONFIG['model_type'] == 'ordinal':\n",
        "        print(\"  Warning: Using standard model with {} loss (ordinal model requires ordinal loss)\".format(CONFIG['loss_type']))\n",
        "elif CONFIG['loss_type'] == 'ordinal':\n",
        "    effective_model_type = 'ordinal'\n",
        "\n",
        "def create_model(model_type, seed=None):\n",
        "    \"\"\"Create a model with optional seed for ensemble diversity.\"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "\n",
        "    if model_type == 'ordinal':\n",
        "        return OrdinalMetricMatchingModel(**{k: CONFIG[k] for k in ['embedding_dim', 'hidden_dims', 'dropout']})\n",
        "    elif model_type == 'heteroscedastic':\n",
        "        return HeteroscedasticMatchingModel(**{k: CONFIG[k] for k in ['embedding_dim', 'hidden_dims', 'dropout']})\n",
        "    else:\n",
        "        return StandardMetricMatchingModel(**{k: CONFIG[k] for k in ['embedding_dim', 'hidden_dims', 'dropout']})\n",
        "\n",
        "def create_loss(loss_type):\n",
        "    \"\"\"Create loss function based on type.\"\"\"\n",
        "    if loss_type == 'ordinal':\n",
        "        return OrdinalRegressionLoss()\n",
        "    elif loss_type == 'hybrid':\n",
        "        return HybridLoss(ce_weight=1.0, mse_weight=CONFIG.get('hybrid_mse_weight', 0.1))\n",
        "    elif loss_type == 'focal':\n",
        "        return FocalLoss(gamma=CONFIG['focal_gamma'])\n",
        "    elif loss_type == 'heteroscedastic':\n",
        "        return HeteroscedasticLoss()\n",
        "    else:\n",
        "        return nn.CrossEntropyLoss()\n",
        "\n",
        "# For single model training (non-ensemble mode)\n",
        "if not CONFIG.get('use_ensemble', False):\n",
        "    model = create_model(effective_model_type)\n",
        "    model = model.to(device)\n",
        "    criterion = create_loss(CONFIG['loss_type'])\n",
        "else:\n",
        "    # Ensemble mode - will be handled later\n",
        "    model = None\n",
        "    criterion = None\n",
        "\n",
        "# Optimizer with parameter groups (encoder LR vs head LR)\n",
        "# Note: Since we precompute embeddings, model only has head params\n",
        "optimizer = None\n",
        "scheduler = None\n",
        "scaler = None\n",
        "\n",
        "if not CONFIG.get('use_ensemble', False):\n",
        "    # All model params use head LR (since encoder is separate and pre-computed)\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=CONFIG['learning_rate'],  # Head LR\n",
        "        weight_decay=CONFIG['weight_decay']\n",
        "    )\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=CONFIG['lr_patience'],\n",
        "        min_lr=CONFIG['min_lr'], verbose=True\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if CONFIG['use_amp'] else None\n",
        "\n",
        "    print(f\"Model: {effective_model_type} (configured: {CONFIG['model_type']})\")\n",
        "    print(f\"Loss: {CONFIG['loss_type']}\")\n",
        "    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"Learning rate: {CONFIG['learning_rate']:.2e} (head LR)\")\n",
        "else:\n",
        "    print(\"Ensemble mode: Will train multiple models\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fS31aMnJxMzf"
      },
      "id": "fS31aMnJxMzf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# RESUME FROM CHECKPOINT\n",
        "# ============================================================================\n",
        "\n",
        "start_epoch = 0\n",
        "best_rmse = float('inf')\n",
        "\n",
        "if not CONFIG.get('use_ensemble', False):\n",
        "    if CONFIG['resume_from_checkpoint']:\n",
        "        checkpoint_path = find_latest_checkpoint(CONFIG['checkpoint_dir'])\n",
        "        if checkpoint_path:\n",
        "            model, start_epoch, best_rmse = load_checkpoint(checkpoint_path, model, optimizer)\n",
        "            print(f\"Resumed from epoch {start_epoch}\")\n",
        "        else:\n",
        "            print(\"No checkpoint found, starting fresh\")\n",
        "    else:\n",
        "        print(\"Starting fresh training\")\n"
      ],
      "metadata": {
        "id": "UErOIsZbxQBJ"
      },
      "id": "UErOIsZbxQBJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TRAINING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device, scaler, gradient_clip):\n",
        "    \"\"\"\n",
        "    Unified training epoch using compute_weighted_loss for consistent per-sample weighting.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        metric_emb, text_emb, target, weights, _ = batch\n",
        "        metric_emb = metric_emb.to(device)\n",
        "        text_emb = text_emb.to(device)\n",
        "        target = target.to(device)\n",
        "        weights = weights.to(device) if CONFIG.get('use_weights', True) else None\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass - handle heteroscedastic separately\n",
        "        if isinstance(criterion, HeteroscedasticLoss):\n",
        "            logits_or_tuple = model(metric_emb, text_emb)  # Returns (mean, logvar)\n",
        "        else:\n",
        "            logits_or_tuple = model(metric_emb, text_emb)  # Returns logits\n",
        "\n",
        "        # Compute weighted loss using unified helper\n",
        "        loss = compute_weighted_loss(criterion, logits_or_tuple, target, weights)\n",
        "\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            if gradient_clip:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if gradient_clip:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, criterion, device, verbose=True):\n",
        "    \"\"\"\n",
        "    Validate model with per-bin RMSE logging and prediction distribution.\n",
        "    Returns RMSE, MAE, and per-bin statistics.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Validating\", disable=not verbose):\n",
        "            metric_emb, text_emb, target, _, _ = batch\n",
        "            metric_emb = metric_emb.to(device)\n",
        "            text_emb = text_emb.to(device)\n",
        "\n",
        "            scores = model.predict_score(metric_emb, text_emb)\n",
        "            # Clamp predictions to valid range [0, 10]\n",
        "            scores = torch.clamp(scores, 0.0, 10.0)\n",
        "            all_preds.extend(scores.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_targets = np.array(all_targets)\n",
        "\n",
        "    # Round predictions for RMSE calculation (matching evaluation)\n",
        "    all_preds_rounded = np.round(all_preds).clip(0, 10)\n",
        "\n",
        "    # Overall metrics\n",
        "    rmse = np.sqrt(mean_squared_error(all_targets, all_preds_rounded))\n",
        "    mae = mean_absolute_error(all_targets, all_preds_rounded)\n",
        "\n",
        "    # Per-bin RMSE (recommended validation check)\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"PER-BIN RMSE ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "        bin_rmses = {}\n",
        "        bin_counts = {}\n",
        "        for score in range(11):\n",
        "            mask = all_targets == score\n",
        "            if np.sum(mask) > 0:\n",
        "                bin_preds = all_preds_rounded[mask]\n",
        "                bin_targets = all_targets[mask]\n",
        "                bin_rmse = np.sqrt(mean_squared_error(bin_targets, bin_preds))\n",
        "                bin_rmses[score] = bin_rmse\n",
        "                bin_counts[score] = np.sum(mask)\n",
        "                print(f\"  Score {score:2d}: RMSE={bin_rmse:5.2f}, Count={bin_counts[score]:4d}\")\n",
        "\n",
        "        # Prediction distribution histogram\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"PREDICTION DISTRIBUTION\")\n",
        "        print(\"=\"*60)\n",
        "        pred_dist = Counter(np.round(all_preds).clip(0, 10).astype(int))\n",
        "        target_dist = Counter(all_targets.astype(int))\n",
        "\n",
        "        print(f\"{'Score':<8} {'Predicted':<12} {'Actual':<12} {'Diff':<8}\")\n",
        "        print(\"-\"*60)\n",
        "        for score in range(11):\n",
        "            pred_count = pred_dist.get(score, 0)\n",
        "            target_count = target_dist.get(score, 0)\n",
        "            pred_pct = 100 * pred_count / len(all_preds) if len(all_preds) > 0 else 0\n",
        "            target_pct = 100 * target_count / len(all_targets) if len(all_targets) > 0 else 0\n",
        "            diff = pred_pct - target_pct\n",
        "            print(f\"{score:<8} {pred_count:5d} ({pred_pct:5.1f}%) {target_count:5d} ({target_pct:5.1f}%) {diff:+6.1f}%\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    return rmse, mae\n"
      ],
      "metadata": {
        "id": "NtFjT3N8xZJX"
      },
      "id": "NtFjT3N8xZJX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TRAINING LOOP\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# ENSEMBLE TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "def compute_engineered_features(metric_embeddings, text_embeddings, metric_indices, standardize=True):\n",
        "    \"\"\"\n",
        "    Compute engineered features for meta-learner with proper normalization.\n",
        "\n",
        "    Args:\n",
        "        metric_embeddings: (M, D) array of metric embeddings\n",
        "        text_embeddings: (N, D) array of text embeddings\n",
        "        metric_indices: (N,) array of metric indices for each sample\n",
        "        standardize: If True, z-score standardize features\n",
        "\n",
        "    Returns:\n",
        "        features: (N, F) array of engineered features (standardized if requested)\n",
        "    \"\"\"\n",
        "    eps = 1e-8\n",
        "    metric_embs = metric_embeddings[metric_indices]  # (N, D)\n",
        "\n",
        "    dot_prod = np.sum(metric_embs * text_embeddings, axis=1)\n",
        "    metric_norm = np.linalg.norm(metric_embs, axis=1) + eps\n",
        "    text_norm = np.linalg.norm(text_embeddings, axis=1) + eps\n",
        "\n",
        "    features = []\n",
        "\n",
        "    # 1. Cosine similarity\n",
        "    features.append((dot_prod / (metric_norm * text_norm)).reshape(-1, 1))\n",
        "\n",
        "    # 2. Raw dot product (simple, distinct from cosine)\n",
        "    # Note: Using raw dot product since cosine already captures normalized similarity\n",
        "    features.append(dot_prod.reshape(-1, 1))\n",
        "\n",
        "    # 3. L1 distance\n",
        "    features.append(np.sum(np.abs(metric_embs - text_embeddings), axis=1).reshape(-1, 1))\n",
        "\n",
        "    # 4. L2 distance\n",
        "    features.append(np.linalg.norm(metric_embs - text_embeddings, axis=1).reshape(-1, 1))\n",
        "\n",
        "    # 5. Elementwise product mean\n",
        "    features.append(np.mean(metric_embs * text_embeddings, axis=1).reshape(-1, 1))\n",
        "\n",
        "    # 6. Text embedding statistics\n",
        "    features.append(np.mean(text_embeddings, axis=1).reshape(-1, 1))\n",
        "    features.append(np.std(text_embeddings, axis=1).reshape(-1, 1))\n",
        "    features.append(np.max(text_embeddings, axis=1).reshape(-1, 1))\n",
        "    features.append(np.min(text_embeddings, axis=1).reshape(-1, 1))\n",
        "\n",
        "    feats = np.concatenate(features, axis=1)\n",
        "\n",
        "    # Standardize features (important for meta-learner stability)\n",
        "    if standardize:\n",
        "        mu = np.nanmean(feats, axis=0)\n",
        "        sigma = np.nanstd(feats, axis=0) + eps\n",
        "        feats = (feats - mu) / sigma\n",
        "\n",
        "    return feats\n",
        "\n",
        "\n",
        "def train_single_fold_model(model, train_loader, val_loader, device, model_type, loss_type, config):\n",
        "    \"\"\"\n",
        "    Train a single model on one fold and return trained model + OOF predictions.\n",
        "\n",
        "    Returns:\n",
        "        trained_model: Best model from training\n",
        "        val_preds: OOF predictions for validation set (aligned with val indices)\n",
        "    \"\"\"\n",
        "    # Create loss\n",
        "    if loss_type == 'hybrid':\n",
        "        criterion = HybridLoss(ce_weight=1.0, mse_weight=CONFIG.get('hybrid_mse_weight', 0.15))\n",
        "    elif loss_type == 'heteroscedastic':\n",
        "        criterion = HeteroscedasticLoss()\n",
        "    elif loss_type == 'ordinal':\n",
        "        criterion = OrdinalRegressionLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Create optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=CONFIG['learning_rate'],\n",
        "        weight_decay=CONFIG['weight_decay']\n",
        "    )\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=CONFIG['lr_patience'],\n",
        "        min_lr=CONFIG['min_lr'], verbose=False\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if CONFIG['use_amp'] else None\n",
        "\n",
        "    # Train model\n",
        "    best_rmse = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(CONFIG['epochs']):\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, scaler, CONFIG.get('gradient_clip'))\n",
        "        val_rmse, val_mae = validate(model, val_loader, criterion, device, verbose=False)\n",
        "\n",
        "        scheduler.step(val_rmse)\n",
        "\n",
        "        if val_rmse < best_rmse:\n",
        "            best_rmse = val_rmse\n",
        "            patience_counter = 0\n",
        "            # Create independent copy of state dict (safer for GPU tensors)\n",
        "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= CONFIG['patience']:\n",
        "                break\n",
        "\n",
        "    # Load best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    # Get OOF predictions\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            metric_emb, text_emb, target, _, _ = batch\n",
        "            metric_emb = metric_emb.to(device)\n",
        "            text_emb = text_emb.to(device)\n",
        "\n",
        "            scores = model.predict_score(metric_emb, text_emb)\n",
        "            scores = torch.clamp(scores, 0.0, 10.0)\n",
        "            val_preds.extend(scores.cpu().numpy())\n",
        "\n",
        "    val_preds = np.array(val_preds)\n",
        "\n",
        "    return model, val_preds\n",
        "\n",
        "\n",
        "def train_ensemble_pipeline(all_folds, full_dataset, train_data, metric_embeddings, text_embeddings, metric_names_map, device):\n",
        "    \"\"\"\n",
        "    Complete ensemble training pipeline:\n",
        "    1. Collect OOF predictions for all models across all folds\n",
        "    2. Compute engineered features\n",
        "    3. Train meta-learner on OOF predictions + features\n",
        "    4. Train calibrator\n",
        "    5. Save everything for inference\n",
        "\n",
        "    Returns:\n",
        "        trained_models: Dict of trained models per fold per model name\n",
        "        meta_learner: Trained Ridge meta-learner\n",
        "        calibrator: Trained IsotonicRegression calibrator\n",
        "        oof_predictions: Dict of OOF predictions per model\n",
        "        oof_targets: True targets\n",
        "        engineered_features: Engineered features array\n",
        "    \"\"\"\n",
        "    from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENSEMBLE TRAINING PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    n_samples = len(train_data)\n",
        "    ensemble_configs = CONFIG.get('ensemble_configs', [])\n",
        "    oof_predictions = {}\n",
        "    oof_targets = np.full(n_samples, np.nan, dtype=float)  # Use NaN sentinel\n",
        "    trained_models = {}\n",
        "\n",
        "    # Initialize OOF arrays for each model with NaN sentinel (not zeros - zero is valid prediction)\n",
        "    for config in ensemble_configs:\n",
        "        model_name = config['name']\n",
        "        oof_predictions[model_name] = np.full(n_samples, np.nan, dtype=float)\n",
        "        trained_models[model_name] = []\n",
        "\n",
        "    # Get metric indices for engineered features\n",
        "    metric_indices = [metric_names_map[rec['metric_name']] for rec in train_data]\n",
        "\n",
        "    # Step 1: Collect OOF predictions for each fold\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 1: Collecting OOF Predictions\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(all_folds):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Fold {fold_idx+1}/{len(all_folds)}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}\")\n",
        "\n",
        "        # Create train/val datasets for this fold\n",
        "        train_dataset = Subset(full_dataset, train_idx)\n",
        "        val_dataset = Subset(full_dataset, val_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
        "\n",
        "        # Store targets for this fold\n",
        "        oof_targets[val_idx] = np.array([int(float(train_data[i]['score'])) for i in val_idx])\n",
        "\n",
        "        # Train each model type on this fold\n",
        "        for config in ensemble_configs:\n",
        "            model_name = config['name']\n",
        "            model_type = config['type']\n",
        "            loss_type = config.get('loss_type', 'hybrid')\n",
        "            seed = config.get('seed', 42)\n",
        "            dropout = config.get('dropout', CONFIG['dropout'])\n",
        "\n",
        "            print(f\"\\nTraining {model_name} (seed={seed}, dropout={dropout}) on fold {fold_idx+1}...\")\n",
        "\n",
        "            # Create model\n",
        "            model = create_model(model_type, seed=seed)\n",
        "            # Update dropout if specified\n",
        "            if hasattr(model, 'dropout'):\n",
        "                model.dropout = nn.Dropout(dropout)\n",
        "\n",
        "            model = model.to(device)\n",
        "\n",
        "            # Train model on this fold and get OOF predictions\n",
        "            trained_model, val_preds = train_single_fold_model(\n",
        "                model, train_loader, val_loader, device,\n",
        "                model_type, loss_type, config\n",
        "            )\n",
        "\n",
        "            # Store OOF predictions (aligned by original indices)\n",
        "            oof_predictions[model_name][val_idx] = val_preds\n",
        "\n",
        "            # Store trained model (for inference later)\n",
        "            # Store state_dict on CPU to save GPU memory\n",
        "            trained_models[model_name].append({\n",
        "                'fold': fold_idx,\n",
        "                'train_idx': train_idx,\n",
        "                'val_idx': val_idx,\n",
        "                'model_state': {k: v.cpu().clone() for k, v in trained_model.state_dict().items()}  # Move to CPU\n",
        "            })\n",
        "\n",
        "            #  Free GPU memory after storing state_dict\n",
        "            del trained_model\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # Calculate RMSE for this fold\n",
        "            val_rmse = np.sqrt(mean_squared_error(oof_targets[val_idx], val_preds))\n",
        "            print(f\"✓ {model_name} Fold {fold_idx+1} RMSE: {val_rmse:.4f}\")\n",
        "\n",
        "    # Step 2: Compute engineered features\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 2: Computing Engineered Features\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    engineered_features = None\n",
        "    if CONFIG.get('use_engineered_features', True):\n",
        "        print(\"Computing engineered features...\")\n",
        "        engineered_features = compute_engineered_features(\n",
        "            metric_embeddings, text_embeddings, metric_indices\n",
        "        )\n",
        "        print(f\" Engineered features shape: {engineered_features.shape}\")\n",
        "\n",
        "        # Save for inference\n",
        "        features_path = os.path.join(CONFIG['output_dir'], 'engineered_features.npy')\n",
        "        np.save(features_path, engineered_features)\n",
        "        print(f\" Saved engineered features to: {features_path}\")\n",
        "\n",
        "    # Step 3: Train meta-learner\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 3: Training Meta-Learner\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Stack OOF predictions\n",
        "    model_names = list(oof_predictions.keys())\n",
        "    X_oof = np.column_stack([oof_predictions[name] for name in model_names])\n",
        "\n",
        "    # Add engineered features if provided\n",
        "    if engineered_features is not None:\n",
        "        X_oof = np.column_stack([X_oof, engineered_features])\n",
        "\n",
        "    y_oof = oof_targets\n",
        "\n",
        "    # NaN-aware filtering: keep rows where at least one model predicted\n",
        "    valid_mask = ~np.isnan(X_oof).all(axis=1)\n",
        "    X = X_oof[valid_mask].copy()\n",
        "    y = y_oof[valid_mask].copy()\n",
        "\n",
        "    print(f\"Meta-learner training samples: {len(X)} (after NaN filtering)\")\n",
        "    print(f\"Meta-learner features: {X.shape[1]} ({len(model_names)} models + {engineered_features.shape[1] if engineered_features is not None else 0} engineered)\")\n",
        "\n",
        "    # Fill NaNs with column means (train-time imputation)\n",
        "    col_mean = np.nanmean(X, axis=0)\n",
        "    nan_mask = np.isnan(X)\n",
        "    if nan_mask.any():\n",
        "        print(f\"  Imputing {nan_mask.sum()} NaN values with column means\")\n",
        "        X[nan_mask] = np.take(col_mean, np.where(nan_mask)[1])\n",
        "\n",
        "    # Standardize features (important for Ridge stability)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    print(f\"✓ Features standardized using StandardScaler\")\n",
        "\n",
        "    # Train Ridge meta-learner\n",
        "    meta_method = CONFIG.get('meta_method', 'ridge')\n",
        "    if meta_method == 'ridge':\n",
        "        meta_learner = Ridge(alpha=1.0)\n",
        "        meta_learner.fit(X_scaled, y)\n",
        "        meta_oof_preds = meta_learner.predict(X_scaled)\n",
        "\n",
        "        print(f\"\\nMeta-learner (Ridge) coefficients:\")\n",
        "        for i, name in enumerate(model_names):\n",
        "            print(f\"  {name}: {meta_learner.coef_[i]:.4f}\")\n",
        "        if engineered_features is not None:\n",
        "            eng_coef_sum = np.sum(meta_learner.coef_[len(model_names):])\n",
        "            print(f\"  Engineered features (sum): {eng_coef_sum:.4f}\")\n",
        "\n",
        "    # Calculate meta-learner RMSE (raw and rounded)\n",
        "    meta_oof_rmse_raw = np.sqrt(mean_squared_error(y, meta_oof_preds))\n",
        "    meta_oof_preds_rounded = np.round(meta_oof_preds).clip(0, 10)\n",
        "    meta_oof_rmse_rounded = np.sqrt(mean_squared_error(y, meta_oof_preds_rounded))\n",
        "\n",
        "    print(f\"\\nMeta-learner RMSE (raw): {meta_oof_rmse_raw:.4f}\")\n",
        "    print(f\"Meta-learner RMSE (rounded): {meta_oof_rmse_rounded:.4f}\")\n",
        "\n",
        "    # Compare with best base model (using raw RMSE for comparison)\n",
        "    base_rmses = {}\n",
        "    for name in model_names:\n",
        "        mask = ~np.isnan(oof_predictions[name])  # NaN-aware masking\n",
        "        if mask.sum() > 0:\n",
        "            base_rmse_raw = np.sqrt(mean_squared_error(oof_targets[mask], oof_predictions[name][mask]))\n",
        "            base_preds_rounded = np.round(oof_predictions[name][mask]).clip(0, 10)\n",
        "            base_rmse_rounded = np.sqrt(mean_squared_error(oof_targets[mask], base_preds_rounded))\n",
        "            base_rmses[name] = base_rmse_raw  # Use raw for comparison\n",
        "\n",
        "    if base_rmses:\n",
        "        best_base_rmse = min(base_rmses.values())\n",
        "        best_base_name = min(base_rmses, key=base_rmses.get)\n",
        "        print(f\"\\nBest base model ({best_base_name}) RMSE (raw): {best_base_rmse:.4f}\")\n",
        "        print(f\"Meta-learner RMSE (raw): {meta_oof_rmse_raw:.4f}\")\n",
        "        print(f\"Meta-learner improvement: {best_base_rmse - meta_oof_rmse_raw:.4f}\")\n",
        "\n",
        "        if meta_oof_rmse_raw < best_base_rmse:\n",
        "            print(\" Meta-learner improves over best base model!\")\n",
        "        else:\n",
        "            print(\" Meta-learner does not improve, consider simpler blending\")\n",
        "\n",
        "    # Step 4: Train calibrator\n",
        "    calibrator = None\n",
        "    calibrated_oof_preds = None\n",
        "    if CONFIG.get('use_calibration', True):\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"STEP 4: Training Calibrator\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "        # Use raw meta-learner predictions (not rounded) for calibration\n",
        "        X_cal = meta_oof_preds.reshape(-1, 1)\n",
        "        y_cal = y  # Raw targets (already filtered to valid_mask)\n",
        "\n",
        "        calibration_method = CONFIG.get('calibration_method', 'isotonic')\n",
        "        if calibration_method == 'isotonic':\n",
        "            calibrator = IsotonicRegression(out_of_bounds='clip')\n",
        "            calibrator.fit(X_cal.flatten(), y_cal)\n",
        "            calibrated_oof_preds = calibrator.transform(meta_oof_preds)\n",
        "        else:\n",
        "            # Platt scaling (LogisticRegression)\n",
        "            from sklearn.linear_model import LogisticRegression\n",
        "            calibrator = LogisticRegression()\n",
        "            calibrator.fit(X_cal, (y_cal * 10).astype(int))\n",
        "            calibrated_oof_preds = calibrator.predict_proba(X_cal).dot(np.arange(11)) / 10.0\n",
        "\n",
        "        # Calculate calibrated RMSE (raw and rounded)\n",
        "        calibrated_rmse_raw = np.sqrt(mean_squared_error(y_cal, calibrated_oof_preds))\n",
        "        calibrated_oof_preds_rounded = np.round(calibrated_oof_preds).clip(0, 10)\n",
        "        calibrated_rmse_rounded = np.sqrt(mean_squared_error(y_cal, calibrated_oof_preds_rounded))\n",
        "\n",
        "        print(f\"Meta-learner OOF RMSE (raw): {meta_oof_rmse_raw:.4f}\")\n",
        "        print(f\"Meta-learner OOF RMSE (rounded): {meta_oof_rmse_rounded:.4f}\")\n",
        "        print(f\"Calibrated OOF RMSE (raw): {calibrated_rmse_raw:.4f}\")\n",
        "        print(f\"Calibrated OOF RMSE (rounded): {calibrated_rmse_rounded:.4f}\")\n",
        "        print(f\"Calibration improvement (raw): {meta_oof_rmse_raw - calibrated_rmse_raw:.4f}\")\n",
        "        print(f\"Calibration improvement (rounded): {meta_oof_rmse_rounded - calibrated_rmse_rounded:.4f}\")\n",
        "\n",
        "        if calibrated_rmse_raw < meta_oof_rmse_raw:\n",
        "            print(\"  Calibration improves predictions (raw RMSE)!\")\n",
        "        else:\n",
        "            print(\"  Calibration does not improve (raw RMSE), may skip in production\")\n",
        "\n",
        "    # Step 5: Diagnostic report\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 5: Diagnostic Report\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Per-bin RMSE\n",
        "    print(\"\\nPer-bin RMSE (by score):\")\n",
        "    print(f\"{'Score':<8} \" + \" \".join([f\"{name[:10]:<12}\" for name in model_names]) + \" Meta\")\n",
        "    print(\"-\" * (8 + 13 * (len(model_names) + 1)))\n",
        "\n",
        "    for score in range(11):\n",
        "        mask = oof_targets == score\n",
        "        if mask.sum() > 0:\n",
        "            row = f\"{score:<8} \"\n",
        "            for name in model_names:\n",
        "                if mask.sum() > 0:\n",
        "                    preds = oof_predictions[name][mask]\n",
        "                    targets = oof_targets[mask]\n",
        "                    bin_rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "                    row += f\"{bin_rmse:>12.3f} \"\n",
        "                else:\n",
        "                    row += f\"{'N/A':>12} \"\n",
        "\n",
        "            # Meta-learner per-bin RMSE (only samples in valid_mask)\n",
        "            meta_mask = mask & valid_mask\n",
        "            if meta_mask.sum() > 0:\n",
        "                # Get indices within valid_mask that match score mask\n",
        "                score_indices_in_valid = np.where(mask[valid_mask])[0]\n",
        "                if len(score_indices_in_valid) > 0:\n",
        "                    meta_preds_subset = meta_oof_preds[score_indices_in_valid]\n",
        "                    targets_subset = y[score_indices_in_valid]\n",
        "                    bin_rmse = np.sqrt(mean_squared_error(targets_subset, meta_preds_subset))\n",
        "                    row += f\"{bin_rmse:>12.3f} \"\n",
        "                else:\n",
        "                    row += f\"{'N/A':>12} \"\n",
        "            else:\n",
        "                row += f\"{'N/A':>12} \"\n",
        "            print(row)\n",
        "\n",
        "    # Correlation matrix of errors\n",
        "    print(\"\\nCorrelation matrix (lower = more diverse, better):\")\n",
        "    errors = {}\n",
        "    common_mask = np.ones(len(oof_targets), dtype=bool)\n",
        "    for name in model_names:\n",
        "        mask = ~np.isnan(oof_predictions[name])  # NaN-aware masking\n",
        "        errors[name] = oof_predictions[name][mask] - oof_targets[mask]\n",
        "        common_mask &= mask\n",
        "\n",
        "    # Filter common_mask to valid_mask for meta comparisons\n",
        "    common_mask = common_mask & valid_mask\n",
        "\n",
        "    if common_mask.sum() > 0:\n",
        "        error_matrix = np.column_stack([errors[name][common_mask] for name in model_names])\n",
        "        corr_matrix = np.corrcoef(error_matrix.T)\n",
        "\n",
        "        print(f\"{'':<12} \" + \" \".join([f\"{name[:10]:<12}\" for name in model_names]))\n",
        "        print(\"-\" * (12 + 13 * len(model_names)))\n",
        "        for i, name in enumerate(model_names):\n",
        "            row = f\"{name[:12]:<12} \"\n",
        "            for j in range(len(model_names)):\n",
        "                row += f\"{corr_matrix[i, j]:>12.3f} \"\n",
        "            print(row)\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Save everything\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SAVING ENSEMBLE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Save OOF predictions (with NaN sentinels)\n",
        "    oof_path = os.path.join(CONFIG['output_dir'], 'oof_predictions.npz')\n",
        "    np.savez(oof_path, **{name: oof_predictions[name] for name in model_names}, targets=oof_targets)\n",
        "    print(f\" Saved OOF predictions to: {oof_path}\")\n",
        "\n",
        "    # Save meta-learner\n",
        "    if meta_learner is not None:\n",
        "        meta_path = os.path.join(CONFIG['output_dir'], 'meta_learner.pkl')\n",
        "        with open(meta_path, 'wb') as f:\n",
        "            pickle.dump(meta_learner, f)\n",
        "        print(f\"Saved meta-learner to: {meta_path}\")\n",
        "\n",
        "    # Save scaler\n",
        "    if 'scaler' in locals() and scaler is not None:\n",
        "        scaler_path = os.path.join(CONFIG['output_dir'], 'meta_scaler.pkl')\n",
        "        with open(scaler_path, 'wb') as f:\n",
        "            pickle.dump(scaler, f)\n",
        "        print(f\" Saved meta-learner scaler to: {scaler_path}\")\n",
        "\n",
        "    # Save calibrator\n",
        "    if calibrator is not None:\n",
        "        cal_path = os.path.join(CONFIG['output_dir'], 'calibrator.pkl')\n",
        "        with open(cal_path, 'wb') as f:\n",
        "            pickle.dump(calibrator, f)\n",
        "        print(f\" Saved calibrator to: {cal_path}\")\n",
        "\n",
        "    # Save column means for NaN imputation\n",
        "    col_mean_path = os.path.join(CONFIG['output_dir'], 'meta_col_means.npy')\n",
        "    np.save(col_mean_path, col_mean)\n",
        "    print(f\" Saved column means for NaN imputation to: {col_mean_path}\")\n",
        "\n",
        "    # Save trained models\n",
        "    for model_name, fold_models in trained_models.items():\n",
        "        for fold_info in fold_models:\n",
        "            fold = fold_info['fold']\n",
        "            model_path = os.path.join(CONFIG['output_dir'], f'{model_name}_fold{fold+1}.pth')\n",
        "            torch.save(fold_info['model_state'], model_path)\n",
        "        print(f\" Saved {len(fold_models)} models for {model_name}\")\n",
        "\n",
        "    # Save ensemble configuration for inference\n",
        "    ensemble_config_path = os.path.join(CONFIG['output_dir'], 'ensemble_configs.pkl')\n",
        "    with open(ensemble_config_path, 'wb') as f:\n",
        "        pickle.dump(ensemble_configs, f)\n",
        "    print(f\"Saved ensemble configuration to: {ensemble_config_path}\")\n",
        "\n",
        "    # Save training feature statistics (for test set standardization)\n",
        "    if engineered_features is not None:\n",
        "        train_feature_stats = {\n",
        "            'mu': np.nanmean(engineered_features, axis=0),\n",
        "            'sigma': np.nanstd(engineered_features, axis=0) + 1e-8\n",
        "        }\n",
        "        train_stats_path = os.path.join(CONFIG['output_dir'], 'train_feature_stats.pkl')\n",
        "        with open(train_stats_path, 'wb') as f:\n",
        "            pickle.dump(train_feature_stats, f)\n",
        "        print(f\" Saved training feature statistics to: {train_stats_path}\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return trained_models, meta_learner, calibrator, oof_predictions, oof_targets, engineered_features\n"
      ],
      "metadata": {
        "id": "5gx2tEm3xfcI"
      },
      "id": "5gx2tEm3xfcI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a2f11c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-31T19:32:14.208158Z",
          "iopub.status.busy": "2025-10-31T19:32:14.207924Z",
          "iopub.status.idle": "2025-10-31T19:36:02.674536Z",
          "shell.execute_reply": "2025-10-31T19:36:02.673358Z"
        },
        "papermill": {
          "duration": 228.498976,
          "end_time": "2025-10-31T19:36:02.695086",
          "exception": true,
          "start_time": "2025-10-31T19:32:14.196110",
          "status": "failed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "d2d6929433744b55936340e43aaa4e80"
          ]
        },
        "id": "32a2f11c",
        "outputId": "f2e9b0fc-aa62-4331-e114-9031b4050aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
            "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
            "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
            "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
            "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-31 19:34:06.936124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761939247.328688      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761939247.441959      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DA5401 - Data Challenge\n",
            "============================================================\n",
            "PyTorch: 2.6.0+cu124\n",
            "CUDA: True\n",
            "GPU: Tesla T4\n",
            "============================================================\n",
            "\n",
            "Loading data...\n",
            "Found data at: /kaggle/input/da5401\n",
            "Loaded 5000 training samples\n",
            "\n",
            "============================================================\n",
            "Generating Synthetic Negatives (Option 2)\n",
            "============================================================\n",
            "Creating 500 synthetic negative samples...\n",
            "  (Misaligning metrics with prompt-response pairs to create low-fitness examples)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating: 100%|██████████| 500/500 [00:00<00:00, 55010.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Added 500 synthetic negatives\n",
            "  Total training samples: 5000 → 5500\n",
            "\n",
            "Distribution BEFORE synthetic negatives:\n",
            "  Score 0:    13 ( 0.26%)\n",
            "  Score 1:     6 ( 0.12%)\n",
            "  Score 2:     5 ( 0.10%)\n",
            "  Score 3:     7 ( 0.14%)\n",
            "  Score 4:     3 ( 0.06%)\n",
            "  Score 5:     1 ( 0.02%)\n",
            "  Score 6:    45 ( 0.90%)\n",
            "  Score 7:    95 ( 1.90%)\n",
            "  Score 8:   259 ( 5.18%)\n",
            "  Score 9:  3124 (62.48%)\n",
            "  Score 10:  1442 (28.84%)\n",
            "\n",
            "Distribution AFTER synthetic negatives:\n",
            "  Score 0:    13 ( 0.24%)\n",
            "  Score 1:   113 ( 2.05%)\n",
            "  Score 2:    72 ( 1.31%)\n",
            "  Score 3:    83 ( 1.51%)\n",
            "  Score 4:    90 ( 1.64%)\n",
            "  Score 5:    83 ( 1.51%)\n",
            "  Score 6:   126 ( 2.29%)\n",
            "  Score 7:    95 ( 1.73%)\n",
            "  Score 8:   259 ( 4.71%)\n",
            "  Score 9:  3124 (56.80%)\n",
            "  Score 10:  1442 (26.22%)\n",
            "============================================================\n",
            "\n",
            "\n",
            "Computing improved sample weights (sqrt inverse frequency)...\n",
            "Original training distribution:\n",
            "  Score 0:    13 ( 0.24%)\n",
            "  Score 1:   113 ( 2.05%)\n",
            "  Score 2:    72 ( 1.31%)\n",
            "  Score 3:    83 ( 1.51%)\n",
            "  Score 4:    90 ( 1.64%)\n",
            "  Score 5:    83 ( 1.51%)\n",
            "  Score 6:   126 ( 2.29%)\n",
            "  Score 7:    95 ( 1.73%)\n",
            "  Score 8:   259 ( 4.71%)\n",
            "  Score 9:  3124 (56.80%)\n",
            "  Score 10:  1442 (26.22%)\n",
            "\n",
            "Computed weights (sqrt inverse frequency, max 8.0):\n",
            "  Score 0: count=  13, weight=8.000\n",
            "  Score 1: count= 113, weight=5.258\n",
            "  Score 2: count=  72, weight=6.587\n",
            "  Score 3: count=  83, weight=6.135\n",
            "  Score 4: count=  90, weight=5.892\n",
            "  Score 5: count=  83, weight=6.135\n",
            "  Score 6: count= 126, weight=4.979\n",
            "  Score 7: count=  95, weight=5.734\n",
            "  Score 8: count= 259, weight=3.473\n",
            "  Score 9: count=3124, weight=1.500 [boosted]\n",
            "  Score 10: count=1442, weight=1.913 [boosted]\n",
            "\n",
            "Loading text encoder...\n",
            "✓ Found existing fine-tuned encoder at: /kaggle/input/best-model-final/encoder_finetune\n",
            "Loading saved encoder (skipping fine-tuning)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Loaded fine-tuned encoder from checkpoint\n",
            "Encoding text sequences...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2d6929433744b55936340e43aaa4e80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/86 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ GPU cache cleared after encoding\n",
            "✓ Saved CV fold indices to: /kaggle/working/cv_folds.pkl\n",
            "Train: 4400, Val: 1100\n",
            "Model: heteroscedastic (configured: heteroscedastic)\n",
            "Loss: heteroscedastic\n",
            "Parameters: 454,332,034\n",
            "Learning rate: 1.00e-04 (head LR)\n",
            "Found checkpoint at: /kaggle/input/best-model-final/checkpoints/best_model_synth.pth\n"
          ]
        },
        {
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_19/197717115.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_latest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'checkpoint_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Resumed from epoch {start_epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_19/197717115.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(filepath, model, optimizer)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# MAIN TRAINING LOOP\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "if CONFIG.get('use_ensemble', False):\n",
        "    # Ensemble training mode - use comprehensive pipeline\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENSEMBLE TRAINING MODE\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Using {len(CONFIG.get('ensemble_configs', []))} ensemble members\")\n",
        "    print(f\"CV folds: {CONFIG.get('n_cv_folds', 5)}\")\n",
        "\n",
        "    # Run comprehensive ensemble pipeline\n",
        "    trained_models, meta_learner, calibrator, oof_predictions, oof_targets, engineered_features = train_ensemble_pipeline(\n",
        "        all_folds, full_dataset, train_data,\n",
        "        metric_embeddings, text_embeddings, metric_names_map, device\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ENSEMBLE TRAINING COMPLETED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"All models, meta-learner, and calibrator saved!\")\n",
        "    print(\"Ready for test_data.json inference! \")\n",
        "\n",
        "else:\n",
        "    # Single model training mode\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"SINGLE MODEL TRAINING MODE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Model: {effective_model_type} (configured: {CONFIG['model_type']})\")\n",
        "    print(f\"Loss: {CONFIG['loss_type']}\")\n",
        "    print(f\"Weight decay: {CONFIG['weight_decay']}\")\n",
        "    print(f\"Patience: {CONFIG['patience']}\")\n",
        "    print(f\"Batch size: {CONFIG['batch_size']}\")\n",
        "    print(f\"Epochs: {CONFIG['epochs']}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    patience_counter = 0\n",
        "    best_epoch = start_epoch\n",
        "    metrics_history = []\n",
        "\n",
        "    for epoch in range(start_epoch, CONFIG['epochs']):\n",
        "        time_minutes = (epoch - start_epoch + 1) * 8 / 60\n",
        "        time_hours = time_minutes / 60\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']} | Time: {time_hours:.1f}h ({time_minutes:.0f}m)\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, scaler, CONFIG.get('gradient_clip'))\n",
        "\n",
        "        val_rmse, val_mae = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        scheduler.step(val_rmse)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val RMSE: {val_rmse:.4f}, Val MAE: {val_mae:.4f}, LR: {current_lr:.2e}\")\n",
        "\n",
        "        metrics_history.append({\n",
        "            'epoch': epoch+1,\n",
        "            'train_loss': train_loss,\n",
        "            'val_rmse': val_rmse,\n",
        "            'val_mae': val_mae,\n",
        "            'lr': current_lr\n",
        "        })\n",
        "\n",
        "        if val_rmse < best_rmse:\n",
        "            best_rmse = val_rmse\n",
        "            best_epoch = epoch + 1\n",
        "            patience_counter = 0\n",
        "            print(f\">>> NEW BEST RMSE: {best_rmse:.4f} (Epoch {best_epoch})\")\n",
        "\n",
        "            save_checkpoint(model, optimizer, epoch, best_rmse,\n",
        "                           os.path.join(CONFIG['checkpoint_dir'], 'best_model_synth.pth'))\n",
        "            torch.save(model.state_dict(), os.path.join(CONFIG['output_dir'], 'best_model_synth.pth'))\n",
        "            print(\"    Model saved!\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"    Patience: {patience_counter}/{CONFIG['patience']}\")\n",
        "\n",
        "        if CONFIG['auto_save'] and (epoch + 1) % CONFIG['save_interval'] == 0:\n",
        "            checkpoint_path = os.path.join(CONFIG['checkpoint_dir'], f'checkpoint_epoch_{epoch+1}.pth')\n",
        "            save_checkpoint(model, optimizer, epoch, best_rmse, checkpoint_path)\n",
        "\n",
        "        if patience_counter >= CONFIG['patience']:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        # Periodic memory cleanup to prevent OOM\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"TRAINING COMPLETED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Best RMSE: {best_rmse:.4f}\")\n",
        "    print(f\"Best epoch: {best_epoch}/{epoch+1}\")\n",
        "    print(f\"Total epochs: {epoch+1}\")\n",
        "    print(f\"Final LR: {current_lr:.2e}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    final_checkpoint = os.path.join(CONFIG['checkpoint_dir'], 'final_model.pth')\n",
        "    save_checkpoint(model, optimizer, epoch, best_rmse, final_checkpoint)\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_history)\n",
        "    metrics_df.to_csv(os.path.join(CONFIG['output_dir'], 'training_metrics.csv'), index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SAVED FILES\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Best model: /kaggle/working/best_model_synth.pth\")\n",
        "    print(f\"Checkpoints: /kaggle/working/checkpoints/\")\n",
        "    print(f\"Metrics: /kaggle/working/training_metrics.csv\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\n Model achieved RMSE: {best_rmse:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14294892,
          "isSourceIdPinned": false,
          "sourceId": 118082,
          "sourceType": "competition"
        },
        {
          "datasetId": 8612333,
          "sourceId": 13558754,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8618334,
          "sourceId": 13571031,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 272350502,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 237.626723,
      "end_time": "2025-10-31T19:36:06.768566",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-10-31T19:32:09.141843",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}